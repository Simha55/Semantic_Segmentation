{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Satellite_segmentation_deeplabv3plus.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "pGMWILR69Pcw"
      },
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "81WoXP_Q9Pc0"
      },
      "source": [
        "!pip install -q -U segmentation-models-pytorch albumentations > /dev/null\n",
        "import segmentation_models_pytorch as smp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c0N3LiGE9Pc3"
      },
      "source": [
        "DATA_DIR = '../input/deepglobe-road-extraction-dataset'\n",
        "\n",
        "metadata_df = pd.read_csv(os.path.join(DATA_DIR, 'metadata.csv'))\n",
        "metadata_df = metadata_df[metadata_df['split']=='train']\n",
        "metadata_df = metadata_df[['image_id', 'sat_image_path', 'mask_path']]\n",
        "metadata_df['sat_image_path'] = metadata_df['sat_image_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "metadata_df['mask_path'] = metadata_df['mask_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n",
        "# Shuffle DataFrame\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Perform 90/10 split for train / val\n",
        "valid_df = metadata_df.sample(frac=0.1, random_state=42)\n",
        "train_df = metadata_df.drop(valid_df.index)\n",
        "len(train_df), len(valid_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rmTGMjLP9Pc5"
      },
      "source": [
        "class_dict = pd.read_csv(os.path.join(DATA_DIR, 'class_dict.csv'))\n",
        "# Get class names\n",
        "class_names = class_dict['name'].tolist()\n",
        "# Get class RGB values\n",
        "class_rgb_values = class_dict[['r','g','b']].values.tolist()\n",
        "\n",
        "print('All dataset classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8g_LOzWZ9Pc9"
      },
      "source": [
        "# Useful to shortlist specific classes in datasets with large number of classes\n",
        "select_classes = ['background', 'road']\n",
        "\n",
        "# Get RGB values of required classes\n",
        "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
        "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
        "\n",
        "print('Selected classes and their corresponding RGB values in labels:')\n",
        "print('Class Names: ', class_names)\n",
        "print('Class RGB values: ', class_rgb_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R_L6HBUP9PdA"
      },
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "\n",
        "    n_images = len(images)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    for idx, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n_images, idx + 1)\n",
        "        plt.xticks([]); \n",
        "        plt.yticks([])\n",
        "        # get title from the parameter names\n",
        "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Perform one hot encoding on label\n",
        "def one_hot_encode(label, label_values):\n",
        " \n",
        "    semantic_map = []\n",
        "    for colour in label_values:\n",
        "        equality = np.equal(label, colour)\n",
        "        class_map = np.all(equality, axis = -1)\n",
        "        semantic_map.append(class_map)\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "\n",
        "    return semantic_map\n",
        "    \n",
        "# Perform reverse one-hot-encoding on labels / preds\n",
        "def reverse_one_hot(image):\n",
        " \n",
        "    x = np.argmax(image, axis = -1)\n",
        "    return x\n",
        "\n",
        "# Perform colour coding on the reverse-one-hot outputs\n",
        "def colour_code_segmentation(image, label_values):\n",
        "\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wUxVHJfI9PdE"
      },
      "source": [
        "class RoadsDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(\n",
        "            self, \n",
        "            df,\n",
        "            class_rgb_values=None, \n",
        "            augmentation=None, \n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.image_paths = df['sat_image_path'].tolist()\n",
        "        self.mask_paths = df['mask_path'].tolist()\n",
        "        \n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read images and masks\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # one-hot-encode the mask\n",
        "        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n",
        "        \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "            \n",
        "        return image, mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        # return length of \n",
        "        return len(self.image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoYgJAsI9PdG"
      },
      "source": [
        "#### Visualize Sample Image and Mask ðŸ“ˆ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vRX2N6ON9PdG"
      },
      "source": [
        "dataset = RoadsDataset(train_df, class_rgb_values=select_class_rgb_values)\n",
        "random_idx = random.randint(0, len(dataset)-1)\n",
        "image, mask = dataset[2]\n",
        "\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwrG-QjD9PdI"
      },
      "source": [
        "### Defining Augmentations ðŸ™ƒ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZBCtwCyM9PdI"
      },
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        album.HorizontalFlip(p=0.5),\n",
        "        album.VerticalFlip(p=0.5),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn=None):\n",
        "\n",
        "    _transform = []\n",
        "    if preprocessing_fn:\n",
        "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
        "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
        "        \n",
        "    return album.Compose(_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdblt8KV9PdJ"
      },
      "source": [
        "#### Visualize Augmented Images & Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vaFsFp9J9PdK"
      },
      "source": [
        "augmented_dataset = RoadsDataset(\n",
        "    train_df, \n",
        "    augmentation=get_training_augmentation(),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "random_idx = random.randint(0, len(augmented_dataset)-1)\n",
        "\n",
        "# Different augmentations on image/mask pairs\n",
        "for idx in range(3):\n",
        "    image, mask = augmented_dataset[idx]\n",
        "    visualize(\n",
        "        original_image = image,\n",
        "        ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "        one_hot_encoded_mask = reverse_one_hot(mask)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSkitYg9PdM"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4hYRy0oV9PdN"
      },
      "source": [
        "ENCODER = 'resnet50'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = select_classes\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "\n",
        "# create segmentation model with pretrained encoder\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name=ENCODER, \n",
        "    encoder_weights=ENCODER_WEIGHTS, \n",
        "    classes=len(CLASSES), \n",
        "    activation=ACTIVATION,\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNCyF7NJ9PdN"
      },
      "source": [
        "#### Get Train / Val DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cvOEUs2h9PdO"
      },
      "source": [
        "# Get train and val dataset instances\n",
        "train_dataset = RoadsDataset(\n",
        "    train_df, \n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "valid_dataset = RoadsDataset(\n",
        "    valid_df, \n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# Get train and val data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1n5XoA59PdP"
      },
      "source": [
        "#### Set Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "njIEEQOm9PdP"
      },
      "source": [
        "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
        "TRAINING = True\n",
        "\n",
        "# Set num of epochs\n",
        "EPOCHS = 3\n",
        "\n",
        "# Set device: `cuda` or `cpu`\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define loss function\n",
        "loss = smp.utils.losses.DiceLoss()\n",
        "\n",
        "# define metrics\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "\n",
        "# define learning rate scheduler (not used in this NB)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")\n",
        "\n",
        "# load best saved model checkpoint from previous commit (if present)\n",
        "if os.path.exists('../input/road-extraction-from-satellite-images-deeplabv3/best_model.pth'):\n",
        "    model = torch.load('../input/road-extraction-from-satellite-images-deeplabv3/best_model.pth', map_location=DEVICE)\n",
        "    print('Loaded pre-trained DeepLabV3+ model!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5YJEBbcr9PdQ"
      },
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd_iTCYk9PdR"
      },
      "source": [
        "### Training DeepLabV3+"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r35aWls29PdS"
      },
      "source": [
        "%%time\n",
        "\n",
        "if TRAINING:\n",
        "\n",
        "    best_iou_score = 0.0\n",
        "    train_logs_list, valid_logs_list = [], []\n",
        "\n",
        "    for i in range(0, EPOCHS):\n",
        "\n",
        "        # Perform training & validation\n",
        "        print('\\nEpoch: {}'.format(i))\n",
        "        train_logs = train_epoch.run(train_loader)\n",
        "        valid_logs = valid_epoch.run(valid_loader)\n",
        "        train_logs_list.append(train_logs)\n",
        "        valid_logs_list.append(valid_logs)\n",
        "\n",
        "        # Save model if a better val IoU score is obtained\n",
        "        if best_iou_score < valid_logs['iou_score']:\n",
        "            best_iou_score = valid_logs['iou_score']\n",
        "            torch.save(model, './best_model.pth')\n",
        "            print('Model saved!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vn8Wf9X9PdV"
      },
      "source": [
        "### Prediction on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "niYp2p9K9PdW"
      },
      "source": [
        "# load best saved model checkpoint from the current run\n",
        "if os.path.exists('./best_model.pth'):\n",
        "    best_model = torch.load('./best_model.pth', map_location=DEVICE)\n",
        "    print('Loaded DeepLabV3+ model from this run.')\n",
        "\n",
        "# load best saved model checkpoint from previous commit (if present)\n",
        "elif os.path.exists('../input/road-extraction-from-satellite-images-deeplabv3/best_model.pth'):\n",
        "    best_model = torch.load('../input/road-extraction-from-satellite-images-deeplabv3/best_model.pth', map_location=DEVICE)\n",
        "    print('Loaded DeepLabV3+ model from a previous commit.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HHJXsCtO9PdX"
      },
      "source": [
        "# create test dataloader to be used with DeepLabV3+ model (with preprocessing operation: to_tensor(...))\n",
        "test_dataset = RoadsDataset(\n",
        "    valid_df, \n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset)\n",
        "\n",
        "# test dataset for visualization (without preprocessing augmentations & transformations)\n",
        "test_dataset_vis = RoadsDataset(\n",
        "    valid_df,\n",
        "    class_rgb_values=select_class_rgb_values,\n",
        ")\n",
        "\n",
        "# get a random test image/mask index\n",
        "random_idx = random.randint(0, len(test_dataset_vis)-1)\n",
        "image, mask = test_dataset_vis[random_idx]\n",
        "\n",
        "visualize(\n",
        "    original_image = image,\n",
        "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n",
        "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pAbESyYT9PdX"
      },
      "source": [
        "sample_preds_folder = 'sample_predictions/'\n",
        "if not os.path.exists(sample_preds_folder):\n",
        "    os.makedirs(sample_preds_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v94dJf509PdY"
      },
      "source": [
        "for idx in range(len(test_dataset)):\n",
        "\n",
        "    image, gt_mask = test_dataset[idx]\n",
        "    image_vis = test_dataset_vis[idx][0].astype('uint8')\n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "    # Predict test image\n",
        "    pred_mask = best_model(x_tensor)\n",
        "    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
        "    # Convert pred_mask from `CHW` format to `HWC` format\n",
        "    pred_mask = np.transpose(pred_mask,(1,2,0))\n",
        "    # Get prediction channel corresponding to foreground\n",
        "    pred_road_heatmap = pred_mask[:,:,select_classes.index('road')]\n",
        "    pred_mask = colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values)\n",
        "    # Convert gt_mask from `CHW` format to `HWC` format\n",
        "    gt_mask = np.transpose(gt_mask,(1,2,0))\n",
        "    gt_mask = colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values)\n",
        "    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n",
        "    \n",
        "    visualize(\n",
        "        original_image = image_vis,\n",
        "        ground_truth_mask = gt_mask,\n",
        "        predicted_mask = pred_mask,\n",
        "        pred_road_heatmap = pred_road_heatmap\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu8EPahj9PdY"
      },
      "source": [
        "### Model Evaluation on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aZ37I0dG9PdZ"
      },
      "source": [
        "test_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_logs = test_epoch.run(test_dataloader)\n",
        "print(\"Evaluation on Test Data: \")\n",
        "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
        "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Befow1v49PdZ"
      },
      "source": [
        "### Plot Dice Loss & IoU Metric for Train vs. Val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PDBMsS9O9Pda"
      },
      "source": [
        "train_logs_df = pd.DataFrame(train_logs_list)\n",
        "valid_logs_df = pd.DataFrame(valid_logs_list)\n",
        "train_logs_df.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6jamMGzH9Pda"
      },
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('IoU Score', fontsize=20)\n",
        "plt.title('IoU Score Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('iou_score_plot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3pyMSLva9Pda"
      },
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(), lw=3, label = 'Train')\n",
        "plt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(), lw=3, label = 'Valid')\n",
        "plt.xlabel('Epochs', fontsize=20)\n",
        "plt.ylabel('Dice Loss', fontsize=20)\n",
        "plt.title('Dice Loss Plot', fontsize=20)\n",
        "plt.legend(loc='best', fontsize=16)\n",
        "plt.grid()\n",
        "plt.savefig('dice_loss_plot.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}